dist: focal
env:
  global:
    # include $HOME/.local/bin for `aws`
    - PATH=$HOME/.local/bin:$PATH
    - TRAVIS_BUILD_SHARED_STORAGE="&{TRAVIS_BUILD_DIR}/build-stages-shared-storage/${TRAVIS_BUILD_NUMBER}"
    - AWS_S3_BUILD_SHARED_STORAGE="s3://aws-log-forwarder-travis-build-shared-storage/${TRAVIS_BUILD_NUMBER}"
    - AWS_CLOUDWATCH_LOGS_LOG_GROUP="/aws/lambda/aws-log-forwarder-e2e-build-${TRAVIS_BUILD_NUMBER}"
    - AWS_CLOUDWATCH_LOGS_LOG_STREAM="aws-log-forwarder-e2e-build-${TRAVIS_BUILD_NUMBER}-stream"
language: shell
notifications:
  email:
    on_success: never
stages:
- unit_tests
- build
- e2e_tests
- deployment
jobs:
  include:
    - stage: unit_tests
      name: Execute unit tests & linting
      language: shell
      services: docker
      script:
        - docker build -f pipeline/Dockerfile -t lambda_image .
        - docker run --rm lambda_image bash -c 'python3 -m pylint --rcfile=pipeline/pylint.cfg $(find src/ -name "*.py")'
        - docker run --rm lambda_image bash -c 'cd src && python3 -m pytest -v ../tests/unit'
    - stage: build
      name: Build AWS Lambda package
      #if: tag =~ /^release.*$/
      language: shell
      services: docker
      install:
        # set up awscli packages
        - python3 -m pip install --user awscli
      before_script:
        # set up shared storage for build artifacts
        - mkdir -p $TRAVIS_BUILD_SHARED_STORAGE
      script:
        - docker run --rm -v `pwd`:/var/task amazon/aws-sam-cli-build-image-python3.8 bash -c './build-release-package.sh'
      after_success:
        - cp -p dynatrace-aws-log-forwarder.zip $TRAVIS_BUILD_SHARED_STORAGE
        - aws s3 sync $TRAVIS_BUILD_SHARED_STORAGE $AWS_S3_BUILD_SHARED_STORAGE
    - stage: e2e_tests
      name: Execute e2e tests
      # if: branch = master OR type = pull_request
      if: branch = APM-306464
      language: shell
      services: docker
      install:
        # set up awscli packages
        - python3 -m pip install --user awscli
        # set up e2e packages
        - python3 -m pip install --user -r ./tests/e2e/requirements.txt
      before_script:
        # set up shared storage for build artifacts
        - mkdir -p $TRAVIS_BUILD_SHARED_STORAGE
        - aws s3 sync $AWS_S3_BUILD_SHARED_STORAGE $TRAVIS_BUILD_SHARED_STORAGE
        - cp -p $TRAVIS_BUILD_SHARED_STORAGE/dynatrace-aws-log-forwarder.zip ./tests/e2e
        - cd ./tests/e2e
        - unzip dynatrace-aws-log-forwarder.zip
      script:
        # deploy log forwarder resources reqiured for e2e to AWS
        - ./dynatrace-aws-logs.sh deploy --target-url $DYNATRACE_ENV_URL --target-api-token $DYNATRACE_API_KEY --use-existing-active-gate true --require-valid-certificate $VERIFY_SSL --stack-name aws-log-forwarder-e2e-build-$TRAVIS_BUILD_NUMBER
        # create AWS CloudWatch Logs log groups and assign log streams
        - aws logs create-log-group --log-group-name $AWS_CLOUDWATCH_LOGS_LOG_GROUP
        - aws logs create-log-stream --log-group-name $AWS_CLOUDWATCH_LOGS_LOG_GROUP --log-stream-name $AWS_CLOUDWATCH_LOGS_LOG_STREAM
        # subscribe to AWS CloudWatch Logs log groups
        - ./dynatrace-aws-logs.sh subscribe --log-groups $AWS_CLOUDWATCH_LOGS_LOG_GROUP --stack-name aws-log-forwarder-e2e-build-$TRAVIS_BUILD_NUMBER
        # execute end-to-end test
        - ./main.py --log-group-name $AWS_CLOUDWATCH_LOGS_LOG_GROUP --log-stream-name $AWS_CLOUDWATCH_LOGS_LOG_STREAM
      after_script:
        # unsubscribe from AWS CloudWatch Logs log groups
        - ./dynatrace-aws-logs.sh unsubscribe --log-groups $AWS_CLOUDWATCH_LOGS_LOG_GROUP --stack-name aws-log-forwarder-e2e-build-$TRAVIS_BUILD_NUMBER
        # delete AWS CloudWatch Logs log groups
        - aws logs delete-log-group --log-group-name $AWS_CLOUDWATCH_LOGS_LOG_GROUP
        # delete log forwarder AWS resources
        - aws cloudformation delete-stack --stack-name aws-log-forwarder-e2e-build-$TRAVIS_BUILD_NUMBER
    - stage: deployment
      name: Github Release Deployment
      if: tag =~ /^release.*$/
      language: shell
      services: docker
      install:
        # set up awscli packages
        - python3 -m pip install --user awscli
      script: skip
      before_deploy:
        # set up shared storage for build artifacts
        - mkdir -p $TRAVIS_BUILD_SHARED_STORAGE
        - aws s3 sync $AWS_S3_BUILD_SHARED_STORAGE $TRAVIS_BUILD_SHARED_STORAGE
      deploy:
        provider: releases
        api_key: $GITHUB_RELEASE_API_KEY
        file: $TRAVIS_BUILD_SHARED_STORAGE/dynatrace-aws-log-forwarder.zip
        skip_cleanup: true
        on:
          tags: true